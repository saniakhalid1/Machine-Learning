{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d19547",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# example of loading the mnist dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#from matplotlib import pyplot as plt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# load dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m (trainX, trainy), (testX, testy) \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# example of loading the mnist dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#from matplotlib import pyplot as plt\n",
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "#another way of loadind data from txt file\n",
    "#trainX=np.loadtxt('trainX.txt', dtype=np.uint8)\n",
    "#trainY=np.loadtxt('trainY.txt', dtype=np.uint8)\n",
    "#testX=np.loadtxt('testX.txt', dtype=np.uint8)\n",
    "#testY=np.loadtxt('testY.txt', dtype=np.uint8)\n",
    "#trainX2=trainX[:250]\n",
    "#trainX4=trainX[250:]\n",
    "\n",
    "#trainY2=trainY[:250]\n",
    "#trainY4=trainY[250:]\n",
    "\n",
    "#testX2=testX[:50]\n",
    "#testX4=testX[50:]\n",
    "\n",
    "#testY2=testY[:50]\n",
    "#testY4=testY[50:]\n",
    "\n",
    "\n",
    "#Convert Training data into numpy arrays\n",
    "df = pd.read_csv('trainX.txt' , delimiter=' ' , header=None)\n",
    "Train_X = np.array(df)\n",
    "\n",
    "\n",
    "\n",
    "Train_X = Train_X[:Train_X.shape[0],1:].astype(int)\n",
    "\n",
    "\n",
    "Train_X_2 = Train_X[ : int(Train_X.shape[0] / 2) , :]\n",
    "Train_X_4 = Train_X[int(Train_X.shape[0] / 2) : , :]\n",
    "\n",
    "df = pd.read_csv('trainY.txt' , delimiter=' ' , header=None)\n",
    "Train_Y = np.array(df)\n",
    "Train_Y = Train_Y[:Train_Y.shape[0],1:].ravel().astype(int) \n",
    "print (Train_Y)\n",
    "Train_Y_2 = Train_Y[ : int(Train_Y.shape[0] / 2)]\n",
    "Train_Y_4 = Train_Y[int(Train_Y.shape[0] / 2) : ]\n",
    "\n",
    "\n",
    "#Convert Testing data into numpy arrays\n",
    "df = pd.read_csv('testX.txt' , delimiter=' ' , header=None )\n",
    "Test_X = np.array(df)\n",
    "Test_X = Test_X[:Test_X.shape[0],1:].astype(int)\n",
    "Test_X_2 = Test_X[ : int(Test_X.shape[0] / 2) , :]\n",
    "Test_X_4 = Test_X[int(Test_X.shape[0] / 2) : , :]\n",
    "\n",
    "df = pd.read_csv('testY.txt' , delimiter=' ' , header=None )\n",
    "Test_Y = np.array(df)\n",
    "\n",
    "print (Test_Y.shape , Test_Y)\n",
    "Test_Y = Test_Y[:Test_Y.shape[0],1:].ravel().astype(int) \n",
    "print (Test_Y.shape , Test_Y)\n",
    "Test_Y_2 = Test_Y[ : int(Test_Y.shape[0] / 2) ]\n",
    "Test_Y_4 = Test_Y[int(Test_Y.shape[0] / 2) :]\n",
    "\n",
    "\n",
    "#Calculate probabilities without smooting techniques by using only training data\n",
    "Train_X_2_One_Prob = (Train_X_2.sum(axis=0)) / (Train_X_2.shape[0])\n",
    "Train_X_2_Zero_Prob = 1 - Train_X_2_One_Prob \n",
    "Train_X_4_One_Prob = (Train_X_4.sum(axis=0)) / (Train_X_4.shape[0])\n",
    "Train_X_4_Zero_Prob = 1 - Train_X_4_One_Prob \n",
    "\n",
    "\n",
    "#Calculate probabilities with smooting techniques by using only training data\n",
    "#Train_X_2_One_Prob = (Train_X_2.sum(axis=0) + 1) / (Train_X_2.shape[0] + 2)\n",
    "#Train_X_2_Zero_Prob = 1 - Train_X_2_One_Prob \n",
    "#Train_X_4_One_Prob = (Train_X_4.sum(axis=0) + 1) / (Train_X_4.shape[0] + 2)\n",
    "#Train_X_4_Zero_Prob = 1 - Train_X_4_One_Prob \n",
    "\n",
    "\n",
    "#Fuction to calcuate Accuracy\n",
    "def calculateAccuracy(To_Be_Test , Actual_Results):\n",
    "    global Train_X, Test_X_2 ,Train_X_2_One_Prob , Train_X_2_Zero_Prob , Train_X_4 , Train_X_4_One_Prob , Train_X_4_Zero_Prob\n",
    "    \n",
    "    Prob_Of_2 = np.prod((To_Be_Test * Train_X_2_One_Prob) + ((1 - To_Be_Test) * Train_X_2_Zero_Prob) , axis = 1) * (Train_X_2.shape[0] / Train_X.shape[0])  \n",
    "    Prob_Of_4 = np.prod((To_Be_Test * Train_X_4_One_Prob) + ((1 - To_Be_Test) * Train_X_4_Zero_Prob) , axis = 1) * (Train_X_4.shape[0] / Train_X.shape[0])\n",
    "    \n",
    "    Classified_Results = np.where(Prob_Of_2 >= Prob_Of_4 , 2 , 4 )\n",
    "    unmatch_indexes = np.where(Actual_Results != Classified_Results)[0]\n",
    "    \n",
    "    print ('Total example points in Data set: ' , To_Be_Test.shape[0])\n",
    "    print ('Count of unmatched example points: ' , unmatch_indexes.shape[0])\n",
    "    print ('Unmatched Indexes: ' , unmatch_indexes)  \n",
    "   \n",
    "    Accuracy = np.where(Actual_Results == Classified_Results , 1 , 0).sum() / Actual_Results.shape[0] * 100\n",
    "    return Accuracy\n",
    "\n",
    "\n",
    "#Results\n",
    "print ('Accuracy of Training Data\\n')\n",
    "print ('Accuracy: ' , calculateAccuracy(Train_X , Train_Y) , '%\\n')\n",
    "\n",
    "print ('Accuracy of Training Data 2 Class\\n')\n",
    "print ('Accuracy: ' ,  calculateAccuracy(Train_X_2 , Train_Y_2) , '%\\n')\n",
    "\n",
    "print ('Accuracy of Training Data 4 Class\\n')\n",
    "print ('Accuracy: ' , calculateAccuracy(Train_X_4 , Train_Y_4) , '%\\n')\n",
    "\n",
    "print ('Accuracy of Testing Data\\n')\n",
    "print ('Accuracy: ' , calculateAccuracy(Test_X , Test_Y) , '%\\n')\n",
    "\n",
    "print ('Accuracy of Testing Data 2 Class\\n')\n",
    "print ('Accuracy: ' , calculateAccuracy(Test_X_2 , Test_Y_2) , '%\\n')\n",
    "\n",
    "print ('Accuracy of Testing Data 4 Class\\n')\n",
    "print ('Accuracy: ' , calculateAccuracy(Test_X_4 , Test_Y_4) , '%\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
